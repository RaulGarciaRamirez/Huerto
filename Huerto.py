import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.cluster import DBSCAN
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from sklearn.linear_model import LogisticRegression
import datetime
import requests
from matplotlib.dates import MinuteLocator, DateFormatter
from streamlit_autorefresh import st_autorefresh

# Petici√≥n a la API REST para obtener datos del √∫ltimo mes
def fetch_data_from_api():
    mes_pasado = int((datetime.datetime.now() - datetime.timedelta(days=90)).timestamp()) * 1000
# Funci√≥n para obtener y procesar datos de la √∫ltima semana
@st.cache_data(ttl=60)
def fetch_data_from_api_last_month():
    now = datetime.datetime.now()
    one_month_ago = now - datetime.timedelta(days=30)
    one_month_ago_timestamp = int(one_month_ago.timestamp()) * 1000
    now_timestamp = int(now.timestamp()) * 1000
    url = "https://sensecap.seeed.cc/openapi/list_telemetry_data"
    auth = ('93I2S5UCP1ISEF4F', '6552EBDADED14014B18359DB4C3B6D4B3984D0781C2545B6A33727A4BBA1E46E')
    
    # Par√°metros de la solicitud GET para el √∫ltimo mes
    params = {
        'device_eui': '2CF7F1C044300627',
        'time_start': one_month_ago_timestamp,
        'time_end': now_timestamp
    }

    response = requests.get(url, params=params, auth=auth)

    if response.status_code == 200:
        return response.json()
    else:
        st.error(f"Error al realizar la solicitud. C√≥digo de estado: {response.status_code}")
        return None


def process_api_data(api_data):
    if not api_data:
        return pd.DataFrame(columns=['timestamp', 'CO2', 'temperature', 'humidity'])

    canal_identificacion = api_data['data']['list'][0]
    valores_medidos = api_data['data']['list'][1]

    data = {}
    for tipo_med, _ in zip(canal_identificacion, valores_medidos):
        channel_type = tipo_med[1]
        for valor, timestamp in _:
            fecha = pd.to_datetime(timestamp)
            valor = float(valor) if isinstance(valor, (int, float, str)) else None
            
            if fecha not in data:
                data[fecha] = {'timestamp': fecha}
            
            if channel_type == "4100":  # CO2
                data[fecha]['CO2'] = valor
            elif channel_type == "4098":  # Humedad
                data[fecha]['humidity'] = valor
            elif channel_type == "4097":  # Temperatura
                data[fecha]['temperature'] = valor

    df = pd.DataFrame.from_dict(data, orient='index')

    # Asegurarse de que los datos est√©n ordenados por timestamp
    df = df.sort_values(by='timestamp')
    
    # Eliminar duplicados
    df = df.drop_duplicates(subset='timestamp')
    
    return df

# Detectar anomal√≠as utilizando DBSCAN
def detect_anomalies(df, eps=5, min_samples=20):
    df = df.dropna(subset=['CO2'])  # Eliminar filas con valores NaN en CO2
    X = df[['CO2']].values
    dbscan = DBSCAN(eps=eps, min_samples=min_samples)
    df['anomaly'] = dbscan.fit_predict(X)
    data = {}
    for tipo_med, _ in zip(canal_identificacion, valores_medidos):
        channel_type = tipo_med[1]
        for valor, timestamp in _:
            fecha = pd.to_datetime(timestamp)
            valor = float(valor) if isinstance(valor, (int, float, str)) else None
            
            if fecha not in data:
                data[fecha] = {'timestamp': fecha}
            
            if channel_type == "4100":  # CO2
                data[fecha]['CO2'] = valor
            elif channel_type == "4098":  # Humedad
                data[fecha]['humidity'] = valor
            elif channel_type == "4097":  # Temperatura
                data[fecha]['temperature'] = valor

    df = pd.DataFrame.from_dict(data, orient='index')

    # Asegurarse de que los datos est√©n ordenados por timestamp
    df = df.sort_values(by='timestamp')
    
    # Eliminar duplicados
    df = df.drop_duplicates(subset='timestamp')
    
    return df

# Obtener y procesar los datos de la API del √∫ltimo mes
api_data_last_month = fetch_data_from_api_last_month()
df = process_api_data(api_data_last_month)

# Funci√≥n para realizar DBSCAN
def run_dbscan(df):
    X = df[['CO2', 'temperature', 'humidity']].dropna()
    dbscan = DBSCAN(eps=1, min_samples=10).fit(X)
    df.loc[X.index, 'cluster'] = dbscan.labels_
    return df

# Funci√≥n para realizar la regresi√≥n log√≠stica
def run_logistic_regression(df):
    threshold_temp = 21  # Umbral de temperatura para distinguir d√≠a y noche
    df['is_day'] = df['temperature'] > threshold_temp
    # Asegurarse de que haya al menos dos clases en los datos de destino
    if df['is_day'].nunique() < 2:
        st.error("No hay suficiente variabilidad en los datos para ajustar el modelo de regresi√≥n log√≠stica.")
        return df
    X = df[['temperature', 'humidity']].dropna()
    y = df['is_day']
    model = LogisticRegression()
    model.fit(X, y)
    df['day_pred'] = model.predict(X)
    return df

# Clasificar d√≠a y noche utilizando regresi√≥n log√≠stica
def classify_day_night(df):
    df = df.dropna(subset=['temperature'])
    
    # Crear una columna binaria para d√≠a (1) y noche (0)
    df['is_day'] = df['timestamp'].apply(lambda x: 1 if 7 <= x.hour <= 21 else 0)
    
    X = df[['temperature']]
    y = df['is_day']
    
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)
    
    model = LogisticRegression()
    model.fit(X_train, y_train)
    
    # Evaluar el modelo en el conjunto de prueba
    accuracy = model.score(X_test, y_test)
    st.write(f"Precisi√≥n del modelo: {accuracy:.2f}")
    
    df['day_night_prediction'] = model.predict(scaler.transform(df[['temperature']]))
    
    return df

# Configuraci√≥n de la p√°gina de Streamlit
st.title("Monitor de CO2 en Tiempo Real")

# Funci√≥n para mostrar los datos crudos
def show_raw_data():
    st.subheader("Datos Crudos")
    st.write(df)

# Espacio reservado para la gr√°fica
chart_placeholder = st.empty()
day_night_chart_placeholder = st.empty()

# Funci√≥n para crear y mostrar la gr√°fica de CO2
def plot_data(df):
    fig, ax = plt.subplots()
    ax.plot(df['timestamp'], df['CO2'], label='CO2')
    ax.scatter(df[df['anomaly'] == -1]['timestamp'], df[df['anomaly'] == -1]['CO2'], color='red', label='Anomal√≠as')
    ax.set_xlabel('Tiempo')
    ax.set_ylabel('CO2')
    ax.legend()

    # Ajustar las etiquetas de las fechas
    ax.xaxis.set_major_locator(mdates.DayLocator(interval=7))
    ax.xaxis.set_major_formatter(mdates.DateFormatter('%d-%m-%Y'))
    plt.xticks(rotation=45, ha='right', fontsize=8)  # Rotar y ajustar el tama√±o de las etiquetas

    st.pyplot(fig)

# Funci√≥n para crear y mostrar la gr√°fica de d√≠a y noche
def plot_day_night(df):
    fig, ax = plt.subplots()
    ax.plot(df['timestamp'], df['day_night_prediction'], label='Predicci√≥n D√≠a/Noche', color='purple')
    ax.set_xlabel('Tiempo')
    ax.set_ylabel('D√≠a (1) / Noche (0)')
    ax.legend()

    # Ajustar las etiquetas de las fechas
    ax.xaxis.set_major_locator(mdates.DayLocator(interval=7))
    ax.xaxis.set_major_formatter(mdates.DateFormatter('%d-%m-%Y'))
    plt.xticks(rotation=45, ha='right', fontsize=8)  # Rotar y ajustar el tama√±o de las etiquetas

    st.pyplot(fig)

# Obtener y procesar los datos de la API
api_data = fetch_data_from_api()
df = process_api_data(api_data)

# Detectar anomal√≠as
df = detect_anomalies(df)

# Clasificar d√≠a y noche
df = classify_day_night(df)

# Mostrar la gr√°fica inicial
if not df.empty:
    with chart_placeholder:
        plot_data(df)
    with day_night_chart_placeholder:
        plot_day_night(df)
else:
    st.write("No hay datos disponibles para mostrar.")

# Mantener la aplicaci√≥n actualizada con los nuevos datos cada minuto
# while True:
#     api_data = fetch_data_from_api()
#     df = process_api_data(api_data)
#     if not df.empty:
#         df = detect_anomalies(df)
#         with chart_placeholder:
#             plot_data(df)
#     time.sleep(60)  # Esperar 60 segundos antes de actualizar
# Funci√≥n para mostrar las gr√°ficas de CO2, temperatura y humedad
def show_sensor_data():
    st.subheader("Gr√°ficas de Sensores")
    fig, ax = plt.subplots(3, 1, figsize=(10, 8))

    df_last_50 = df.tail(50)  # Obtener los √∫ltimos 50 registros

    # Gr√°fica de CO2
    df_last_50.plot(x='timestamp', y='CO2', ax=ax[0], title='CO2')
    ax[0].xaxis.set_major_locator(MinuteLocator(interval=5))  # Utilizar MinuteLocator
    ax[0].xaxis.set_major_formatter(DateFormatter('%H:%M'))  # Formatear el eje x como hora:minuto
    ax[0].set_xlabel('Timestamp')
    ax[0].set_ylabel('CO2')

    plt.subplots_adjust(hspace=0.9)  # Ajustar el espaciado vertical entre subgr√°ficas
    plt.subplots_adjust(wspace=0.9)  # Ajustar el espaciado horizontal entre subgr√°ficas

    # Gr√°fica de Temperatura
    df_last_50.plot(x='timestamp', y='temperature', ax=ax[1], title='Temperatura')
    ax[1].xaxis.set_major_locator(MinuteLocator(interval=5))  # Utilizar MinuteLocator
    ax[1].xaxis.set_major_formatter(DateFormatter('%H:%M'))  # Formatear el eje x como hora:minuto
    ax[1].set_xlabel('Timestamp')
    ax[1].set_ylabel('Temperatura')

    plt.subplots_adjust(hspace=0.9)  # Ajustar el espaciado vertical entre subgr√°ficas
    plt.subplots_adjust(wspace=0.9)  # Ajustar el espaciado horizontal entre subgr√°ficas

    # Gr√°fica de Humedad
    df_last_50.plot(x='timestamp', y='humidity', ax=ax[2], title='Humedad')
    ax[2].xaxis.set_major_locator(MinuteLocator(interval=5))  # Utilizar MinuteLocator
    ax[2].xaxis.set_major_formatter(DateFormatter('%H:%M'))  # Formatear el eje x como hora:minuto
    ax[2].set_xlabel('Timestamp')
    ax[2].set_ylabel('Humedad')

    st.pyplot(fig)

def show_analysis_data():
    st.subheader("Gr√°ficas de An√°lisis")

    # Realizar DBSCAN
    df_dbscan = run_dbscan(df)

    # Realizar regresi√≥n log√≠stica
    df_regression = run_logistic_regression(df)
    
    # Obtener los √∫ltimos 50 registros
    df_dbscan_last_50 = df_dbscan.tail(100)
    df_regression_last_50 = df_regression.tail(100)

    # Gr√°ficas de DBSCAN y Regresi√≥n Log√≠stica
    fig, ax = plt.subplots(2, 1, figsize=(10, 8))

    # Gr√°fica de DBSCAN
    df_dbscan_last_50.plot(x='timestamp', y='CO2', ax=ax[0], title='DBSCAN', color='blue', linestyle='-')
    ax[0].scatter(df_dbscan_last_50[df_dbscan_last_50['cluster'] == -1]['timestamp'], df_dbscan_last_50[df_dbscan_last_50['cluster'] == -1]['CO2'], color='red')
    ax[0].xaxis.set_major_locator(MinuteLocator(interval=60))  # Utilizar MinuteLocator
    ax[0].xaxis.set_major_formatter(DateFormatter('%H:%M'))  # Formatear el eje x como hora:minuto
    ax[0].set_xlabel('Timestamp')
    ax[0].set_ylabel('CO2')

    # Indicador de presencia de gente en DBSCAN
    if df_dbscan['cluster'].nunique() > 1:
        st.text("Hay Gente: üî¥‚ö™")
    else:
        st.text("Hay Gente: ‚ö™üü¢")

    plt.subplots_adjust(hspace=0.5)  # Ajustar el espaciado vertical entre subgr√°ficas
    plt.subplots_adjust(wspace=0.5)  # Ajustar el espaciado horizontal entre subgr√°ficas

    # Gr√°fica de Regresi√≥n Log√≠stica
    df_regression_last_50.plot(x='timestamp', y='temperature', ax=ax[1], title='Regresi√≥n Log√≠stica', color='yellow' if df_regression['day_pred'].mean() > 0.5 else 'navy', linestyle='None', marker='o', label='D√≠a' if df_regression['day_pred'].mean() > 0.5 else 'Noche')
    ax[1].xaxis.set_major_locator(MinuteLocator(interval=60))  # Utilizar MinuteLocator
    ax[1].xaxis.set_major_formatter(DateFormatter('%H:%M'))  # Formatear el eje x como hora:minuto
    ax[1].set_xlabel('Timestamp')
    ax[1].set_ylabel('Temperatura')
    ax[1].legend()

    # Indicador de d√≠a/noche en Regresi√≥n Log√≠stica
    if df_regression['day_pred'].mean() > 0.5:
        st.text("Es de D√≠a: ‚òÄÔ∏è")
    else:
        st.text("Es de Noche: üåô")

    st.pyplot(fig)

# Aplicar el dise√±o con tabs
tabs = st.tabs(["Datos Crudos", "Gr√°ficas de Sensores", "Gr√°ficas de An√°lisis"])
with tabs[0]:
    show_raw_data()
with tabs[1]:
    show_sensor_data()
with tabs[2]:
    show_analysis_data()

# A√±adir la funci√≥n para actualizar autom√°ticamente las gr√°ficas cada minuto
st_autorefresh(interval=60000)